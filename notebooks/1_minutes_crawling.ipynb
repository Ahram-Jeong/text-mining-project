{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:22:11.046899Z",
     "start_time": "2024-06-22T09:22:08.987249Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from tika import parser\n",
    "import shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6de4175cc05fc904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:22:11.062411Z",
     "start_time": "2024-06-22T09:22:11.051613Z"
    }
   },
   "source": [
    "# ì œëª©\n",
    "title_list = []\n",
    "# ì²¨ë¶€ íŒŒì¼\n",
    "f_name_list = [] # íŒŒì¼ëª…\n",
    "link_list = [] # url\n",
    "cnt = 0 # filename ì¹´ìš´íŠ¸\n",
    "# text ë³€í™˜\n",
    "txt_list = []"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# HTML ì»¨í…ì¸  ìˆ˜ì§‘\n",
    "for i in tqdm(range(1, 54)) :\n",
    "    min_url = f\"https://www.bok.or.kr/portal/bbs/B0000245/list.do?menuNo=200761&pageIndex={i}\"\n",
    "    res = req.get(min_url)\n",
    "    soup = bs(res.content, \"html.parser\")\n",
    "\n",
    "    links = soup.select(\"div.col.m2.s2.x3.fileLink a\")\n",
    "    titles = soup.select(\"span.titlesub\")\n",
    "\n",
    "    for i in range(len(titles)) :\n",
    "        title_list.append(titles[i].text)\n",
    "\n",
    "    for i in links :\n",
    "        filename = i.get_text().strip()\n",
    "\n",
    "        # í™•ì¥ìê°€ pdfì¸ íŒŒì¼ë§Œ ìˆ˜ì§‘\n",
    "        if filename[-3:] == \"pdf\" :\n",
    "            # íŒŒì¼ëª…\n",
    "            filename = f\"{title_list[cnt]}.pdf\"\n",
    "            f_name_list.append(filename)\n",
    "            cnt += 1\n",
    "\n",
    "            # íŒŒì¼ì˜ ì£¼ì†Œ ê°’\n",
    "            file_addr = \"http://bok.or.kr\" + i[\"href\"]\n",
    "            link_list.append(file_addr)\n",
    "\n",
    "print(len(title_list), len(f_name_list), len(link_list))"
   ],
   "id": "aa3caccb0788840b"
  },
  {
   "cell_type": "code",
   "id": "a5b4f205af992feb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:23:27.998349Z",
     "start_time": "2024-06-22T09:23:27.989301Z"
    }
   },
   "source": [
    "# í•œêµ­ì€í–‰ ê¸ˆìœµí†µí™”ìœ„ì›íšŒ ì˜ì‚¬ë¡ í˜ì´ì§€ HTMLêµ¬ì¡°ê°€ ë°”ë€Œê¸° ì „ê¹Œì§€ë¡œ list ê¸¸ì´ ìˆ˜ì •\n",
    "title_list = title_list[:300]\n",
    "f_name_list = f_name_list[:300]\n",
    "link_list = link_list[:300]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# DataFrame ìƒì„±\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df = pd.DataFrame({\n",
    "    \"title\" : title_list,\n",
    "    \"file\" : f_name_list,\n",
    "    \"url\" : link_list\n",
    "})\n",
    "df"
   ],
   "id": "107a070ff5e889b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€\n",
    "df[\"date\"] = df[\"title\"].str.replace(r\"\\s+\", \"\", regex=True).str.extract(r\"\\((\\d{4}\\.\\d{1,2}\\.\\d{1,2})\\.?\\)$\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y.%m.%d\")\n",
    "df = df.reindex(columns=[\"date\", \"title\", \"file\", \"url\"])\n",
    "df"
   ],
   "id": "206ff3537f32b98d"
  },
  {
   "cell_type": "code",
   "id": "65695b8d-5ead-4e83-ad99-b4017e53ac95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:23:34.303267Z",
     "start_time": "2024-06-22T09:23:34.303267Z"
    }
   },
   "source": [
    "print(df[\"date\"].count())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99c620268dcf5035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:23:34.303267Z",
     "start_time": "2024-06-22T09:23:34.303267Z"
    }
   },
   "source": "df.to_csv(\"../data/minutes_info.csv\", encoding = \"utf8\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63114a2a-04e5-4f3a-91ea-88f14da1b504",
   "metadata": {},
   "source": [
    "## PDF ì˜ì‚¬ë¡ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "id": "241a2a2568a258da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:23:34.303267Z",
     "start_time": "2024-06-22T09:23:34.303267Z"
    }
   },
   "source": [
    "# ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "for i in tqdm(range(len(link_list))) :\n",
    "    try :\n",
    "        res = req.get(link_list[i])\n",
    "        # dir ìƒì„± or í™•ì¸\n",
    "        if not os.path.isdir(\"../data/pdf/\") :\n",
    "            os.mkdir(\"../data/pdf/\")\n",
    "        if res.status_code == 200 :\n",
    "            file_path = os.path.join(\"../data/pdf/\", f_name_list[i])\n",
    "\n",
    "            # íŒŒì¼ ì—´ê¸°, ì“°ê¸°\n",
    "            open(file_path, \"wb\").write(res.content)\n",
    "    except Exception as e :\n",
    "        print(\"Error! : \", e)\n",
    "        continue\n",
    "print(\"CompleteğŸ˜‡\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df5388bc-4b64-417f-9d00-f0d22c199a60",
   "metadata": {},
   "source": [
    "## pdf ğŸ‘‰ text"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9dd3e01-ca80-48bf-a9f8-3acb2abca4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:23:34.303267Z",
     "start_time": "2024-06-22T09:23:34.303267Z"
    }
   },
   "source": [
    "# í´ë” ë‚´ pdfíŒŒì¼ì„ txt íŒŒì¼ë¡œ ë³€ê²½\n",
    "def pdf2txt(source_folder=\"../data/pdf/\", output_folder=\"../data/text/\") :\n",
    "    if not os.path.isdir(\"../data/text/\") :\n",
    "            os.mkdir(\"../data/text/\")\n",
    "    # ì§€ì • í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ (íŒŒì¼ë§Œ)\n",
    "    pdf_files = [f for f in listdir(source_folder) if isfile(join(source_folder, f))]\n",
    "    \n",
    "    try :\n",
    "        for pdf in tqdm(pdf_files) :\n",
    "            pdf_filepath = source_folder + pdf\n",
    "            pdf_tmp_filepath = output_folder + \"tmp.pdf\"\n",
    "\n",
    "            # pdf íŒŒì¼ì„ textë¡œ ë³€í™˜\n",
    "            shutil.copyfile(pdf_filepath, pdf_tmp_filepath)\n",
    "            parsedPDF = parser.from_file(pdf_tmp_filepath)[\"content\"]\n",
    "\n",
    "            #enter ì‚­ì œ\n",
    "            parsedPDF = re.sub(\"\\n\", \"\", parser.from_file(pdf_tmp_filepath)[\"content\"])\n",
    "\n",
    "            output_filepath = (output_folder + pdf).replace(\".pdf\", \".txt\")\n",
    "            \n",
    "            with open(output_filepath, \"w\", -1,\"utf-8\") as f:\n",
    "                print(output_filepath)\n",
    "                f.write(parsedPDF)\n",
    "                f.close()\n",
    "    except Exception as e:\n",
    "        print(\"ì˜¤ë¥˜\", e)\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97a041ce-a586-40a5-add5-79d5fab62c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:23:34.319484Z",
     "start_time": "2024-06-22T09:23:34.319484Z"
    }
   },
   "source": "pdf2txt(source_folder=\"../data/pdf/\", output_folder=\"../data/text/\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0c66458c-5e4f-4aa4-acb6-8a48173774eb",
   "metadata": {},
   "source": [
    "## ì˜ì‚¬ë¡ ì„¹ì…˜ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "id": "42080f40-0dd2-45c4-97ab-bdb669fa8f61",
   "metadata": {},
   "source": [
    "def tidy_sentences(section) :\n",
    "    sentence_enders = re.compile(r\"((?<=[í•¨ìŒë¨ì„ë´„ì§ì›€])(\\s*\\n|\\.|;)|(?<=ë‹¤)\\.)\\s*\")\n",
    "    splits = list((m.start(), m.end()) for m in re.finditer(sentence_enders, section))\n",
    "    starts = [0] + [i[1] for i in splits]\n",
    "    ends = [i[0] for i in splits]\n",
    "    sentences = [section[start:end] for start, end in zip(starts[:-1], ends)]\n",
    "    for i, s in enumerate(sentences):\n",
    "        sentences[i] = (s.replace(\"\\n\", \" \").replace(\" \", \" \")) + \".\"\n",
    "    text = \"\\n\".join(sentences) if len(sentences) > 0 else \"\"\n",
    "    \n",
    "    return sentences, text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "039db3fa-a9dc-44db-9366-e4452e02ed3c",
   "metadata": {},
   "source": [
    "def preprocess_minutes(minutes) :\n",
    "    pos = re.search(\"(.?êµ­ë‚´ì™¸\\s?ê²½ì œ\\s?ë™í–¥.?ê³¼ ê´€ë ¨í•˜ì—¬,?|\\(ê°€\\).+ê²½ì œì „ë§.*|\\(ê°€\\) êµ­ë‚´ì™¸ ê²½ì œë™í–¥ ë° í‰ê°€)\\n?\\s*ì¼ë¶€ ìœ„ì›ì€\", minutes, re.MULTILINE)\n",
    "    s1 = pos.start() if pos else -1\n",
    "    pos = re.search(\"(.?ì™¸í™˜.?êµ­ì œê¸ˆìœµ\\s?ë™í–¥.?ê³¼ ê´€ë ¨í•˜ì—¬.*|\\(ë‚˜\\) ì™¸í™˜.êµ­ì œê¸ˆìœµ\\s?(ë° ê¸ˆìœµì‹œì¥)?\\s?ë™í–¥)\\n?\\s*(ì¼ë¶€ ìœ„ì›ì€|ëŒ€ë¶€ë¶„ì˜ ìœ„ì›ë“¤ì€)\", minutes,re.MULTILINE)\n",
    "    s2 = pos.start() if pos else -1\n",
    "    pos = re.search(\"(.?ê¸ˆìœµì‹œì¥\\s?ë™í–¥.?ê³¼ ê´€ë ¨í•˜ì—¬,?|\\(ë‹¤\\) ê¸ˆìœµì‹œì¥\\s?ë™í–¥)\\n?\\s*ì¼ë¶€ ìœ„ì›ì€\", minutes, re.MULTILINE)\n",
    "    s3 = pos.start() if pos else -1\n",
    "    pos = re.search(\"((\\((ë‹¤|ë¼)\\) )?.?í†µí™”ì •ì±…\\s?ë°©í–¥.?ì— ê´€í•œ í† ë¡ ,?|ì´ìƒê³¼ ê°™ì€ ì˜ê²¬\\s?êµí™˜ì„ ë°”íƒ•ìœ¼ë¡œ.*í†µí™”ì •ì±…\\s?ë°©í–¥.*ì—.*í† ë¡ .*)\\n?\", minutes,re.MULTILINE)\n",
    "    s4 = pos.start() if pos else -1\n",
    "    pos = re.search(\"(\\(4\\) ì •ë¶€ì¸¡ ì—´ì„ì ë°œì–¸.*)\\n?\", minutes, re.MULTILINE)\n",
    "    s5 = pos.start() if pos else -1\n",
    "    pos = re.search(\"(\\(.*\\) í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ ê²°ì •ì— ê´€í•œ ìœ„ì›ë³„ ì˜ê²¬\\s?ê°œì§„|ì´ìƒê³¼ ê°™ì€ í† ë¡ ì— ì´ì–´ .* ê´€í•œ ìœ„ì›ë³„ ì˜ê²¬ê°œì§„ì´ ìˆì—ˆìŒ.*)\\n?\", minutes,re.MULTILINE)\n",
    "    s6 = pos.start() if pos else -1\n",
    "    positer = re.finditer(\"(\\(\\s?.*\\s?\\) ()(ì‹¬ì˜ê²°ê³¼|í† ì˜ê²°ë¡ ))\\n?\", minutes, re.MULTILINE)\n",
    "    s7 = [pos.start() for pos in positer if pos.start() > s6]\n",
    "    s7 = s7[0] if s7 else -1\n",
    "\n",
    "    # êµ­ë‚´ì™¸ ê²½ì œë™í–¥\n",
    "    bos = s1\n",
    "    eos = s2\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else \"\"\n",
    "    pos = re.search(\"(ì¼ë¶€|ëŒ€ë¶€ë¶„ì˜) ìœ„ì›ë“¤?ì€\", section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section1, section1_txt = tidy_sentences(section)\n",
    "\n",
    "    # ì™¸í™˜â€¤êµ­ì œê¸ˆìœµ ë™í–¥\n",
    "    bos = s2\n",
    "    eos = s3 if s3 >= 0 else s4\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else \"\"\n",
    "    pos = re.search(\"(ì¼ë¶€|ëŒ€ë¶€ë¶„ì˜) ìœ„ì›ë“¤?ì€\", section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section2, section2_txt = tidy_sentences(section)\n",
    "\n",
    "    # ê¸ˆìœµì‹œì¥ ë™í–¥\n",
    "    bos = s3\n",
    "    eos = s4\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else \"\"\n",
    "    pos = re.search(\"(ì¼ë¶€|ëŒ€ë¶€ë¶„ì˜) ìœ„ì›ë“¤?ì€\", section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section3, section3_txt = tidy_sentences(section)\n",
    "\n",
    "    # í†µí™”ì •ì±…ë°©í–¥\n",
    "    bos = s4\n",
    "    eos = s5 if s5 >= 0 else s6 if s6 >= 0 else s7\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else \"\"\n",
    "    pos = re.search(\"(ì¼ë¶€|ëŒ€ë¶€ë¶„ì˜) ìœ„ì›ë“¤?ì€\", section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section4, section4_txt = tidy_sentences(section)\n",
    "\n",
    "    # ìœ„ì›ë³„ ì˜ê²¬ ê°œì§„\n",
    "    bos = s6\n",
    "    eos = s7\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else \"\"\n",
    "    pos = re.search(\"(ì¼ë¶€|ëŒ€ë¶€ë¶„ì˜) ìœ„ì›ë“¤?ì€\", section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section5, section5_txt = tidy_sentences(section)\n",
    "\n",
    "    # ì •ë¶€ì¸¡ ì—´ì„ì ë°œì–¸\n",
    "    bos = s5\n",
    "    eos = s6\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else \"\"\n",
    "    pos = re.search(\"ì •ë¶€ì¸¡ ì—´ì„ì ë°œì–¸\", section, re.MULTILINE)\n",
    "    bos = pos.end() + 1 if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section6, section6_txt = tidy_sentences(section)\n",
    "\n",
    "    sections = [\"Economic Situation\", \"Foreign Currency\", \"Financial Markets\",\n",
    "                \"Monetary Policy\", \"Participantsâ€™ Views\", \"Governmentâ€™s View\"]\n",
    "    section_texts = (section1, section2, section3, section4, section5, section6)\n",
    "\n",
    "    return sections, section_texts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8410c9b1-6e15-40de-be51-10a54a611360",
   "metadata": {},
   "source": [
    "def preprocessing(source_folder, output_file) :\n",
    "    # ì§€ì • í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ (íŒŒì¼ë§Œ)\n",
    "    txt_files = [f for f in listdir(source_folder) if isfile(join(source_folder, f))]\n",
    "    txt_files.sort()\n",
    "    df = pd.DataFrame(columns=[\"date\", \"minutes\"])\n",
    "    df[\"Economic Situation\"] = \"\"\n",
    "    df[\"Foreign Currency\"] = \"\"\n",
    "    df[\"Financial Markets\"] = \"\"\n",
    "    df[\"Monetary Policy\"] = \"\"\n",
    "    df[\"Participant Views\"] = \"\"\n",
    "    df[\"Government View\"] = \"\"\n",
    "\n",
    "    df[\"Economic Situation count\"] = \"\"\n",
    "    df[\"Foreign Currency count\"] = \"\"\n",
    "    df[\"Financial Markets count\"] = \"\"\n",
    "    df[\"Monetary Policy count\"] = \"\"\n",
    "    df[\"Participant Views count\"] = \"\"\n",
    "    df[\"Government View count\"] = \"\"\n",
    "\n",
    "    for txt_file in txt_files :\n",
    "        try :\n",
    "            with open(source_folder + txt_file, \"r\", encoding = \"utf-8\") as f :\n",
    "                txt = f.read()\n",
    "                sections, section_texts = preprocess_minutes(txt)\n",
    "\n",
    "                df.loc[len(df)] = [txt_file.split(\"_\")[0],\n",
    "                                   txt,\n",
    "                                   \"@@@\".join(section_texts[0]),\n",
    "                                   \"@@@\".join(section_texts[1]),\n",
    "                                   \"@@@\".join(section_texts[2]),\n",
    "                                   \"@@@\".join(section_texts[3]),\n",
    "                                   \"@@@\".join(section_texts[4]),\n",
    "                                   \"@@@\".join(section_texts[5]),\n",
    "                                   len(section_texts[0]),\n",
    "                                   len(section_texts[1]),\n",
    "                                   len(section_texts[2]),\n",
    "                                   len(section_texts[3]),\n",
    "                                   len(section_texts[4]),\n",
    "                                   len(section_texts[5]),]\n",
    "        except Exception as e:\n",
    "            print(\"ì˜¤ë¥˜\", e)\n",
    "            pass\n",
    "\n",
    "    df.to_csv(output_file, index = False, encoding = \"utf-8\", errors = \"ignore\")\n",
    "    print(\"ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° \", df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "result = preprocessing(source_folder=\"../data/text/\", output_file=\"../data/minutes_contents_df.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c73bbe5-5715-435b-952e-4afaaea9d317",
   "metadata": {},
   "source": [
    "result.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d444abc-1bb0-456b-9a76-cad7858d6333",
   "metadata": {},
   "source": [
    "# ì»¨í…ì¸  DFì— ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€\n",
    "result[\"num_date\"] = result[\"date\"].str.replace(r\"\\s+\", \"\", regex=True).str.replace(r\".txt\", \"\").str.extract(r\"\\((\\d{4}\\.\\d{1,2}\\.\\d{1,2})\\.?\\)$\")\n",
    "result[\"num_date\"] = pd.to_datetime(result[\"num_date\"], format=\"%Y.%m.%d\")\n",
    "# section 2, section 3ë§Œ ë¶„ë¦¬\n",
    "min_result = result.reindex(columns=[\"num_date\", \"date\", \"Foreign Currency\", \"Financial Markets\"])\n",
    "min_result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "437eee72-8aba-4255-8ed0-757448d07b52",
   "metadata": {},
   "source": [
    "## DataFrame ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "id": "e81b040f-2245-46ec-bcc0-16afd3289eb6",
   "metadata": {},
   "source": [
    "result_df = pd.merge(min_result[[\"num_date\", \"Foreign Currency\", \"Financial Markets\"]], df[[\"date\", \"title\"]], left_on = \"num_date\", right_on = \"date\", how = \"inner\")\n",
    "result_df = result_df.reindex(columns=[\"date\", \"title\", \"Foreign Currency\", \"Financial Markets\"])\n",
    "result_df[\"contents\"] = result_df.iloc[:, 2:].apply(lambda x: \"@@@\".join(x), axis=1)\n",
    "result_df[\"contents\"] = result_df[\"contents\"].apply(lambda x: \"\" if x == \"@@@\" else x)\n",
    "result_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db40c961-f244-4e70-99b7-291b58cc09d1",
   "metadata": {},
   "source": [
    "final_df = result_df.reindex(columns = [\"date\", \"title\", \"contents\"])\n",
    "# date íƒ€ì… ì¶œë ¥ í¬ë§· ë³€í™˜\n",
    "final_df[\"date\"] = pd.to_datetime(final_df[\"date\"]).dt.strftime(\"%Y.%m.%d\")\n",
    "final_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f80dcb54-62a7-46f7-8ce3-e59b0dd25569",
   "metadata": {},
   "source": "final_df.to_csv(\"../data/minutes_separation_secion.csv\", index = False)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
